{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashley-ferreira/PHYS449_FinalProject/blob/main/data_loading_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvmvN_PHzi3N"
      },
      "source": [
        "Notebook to load the data in google colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kWHbuobziSN",
        "outputId": "26de7498-3312-4abe-8890-cbf07b73beb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Import Modules:\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "#Import google drive (need to put data folder as shortcut in your local drive My Drive):\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjtsvA98zr0L"
      },
      "outputs": [],
      "source": [
        "#LOAD THE DATA FROM TXT FILE INTO A BATCH:\n",
        "def data_batch(datafile_index, num_images=10, data_file='/content/drive/MyDrive/data/data_g_band.txt'):\n",
        "    '''\n",
        "    Description:\n",
        "        Access datafile.txt, each row is flattened 110x110 image + 1 label string (E, Sp, S0, Irr+Misc).\n",
        "        Returns an augmented batch of num_images X 40.\n",
        "        The labels are converted to 1D vectors (ex: Sp = [0,0,1,0])\n",
        "        Need to give a datafile_index that tells which rows to pick.\n",
        "    Inputs:\n",
        "        datafile_index: index of row in datafile to load. loads rows datafile_index to datafile_index+num_images.\n",
        "        num_images: number of different images to load per batch, total batch size \n",
        "        is 40 X num_images. (default: 10 (for 40X10 = 400 batch size like in paper)\n",
        "        data_file: datafile full path, need to add shortcut to local Drive. (default: '/content/drive/MyDrive/data/data_g_band.txt')\n",
        "    Outputs:\n",
        "        tensor_input_batch_aug: dimensions: (100, 100, num_images X 40). \n",
        "        tensor_label_batch_aug: dimensions: (num_images X 40, 4)\n",
        "    '''\n",
        "\n",
        "    #data_file = 'data_g_band.txt'\n",
        "\n",
        "    #Take batch of num_images rows from datafile:\n",
        "    with open(data_file, 'r') as f:\n",
        "        rows = f.readlines()[datafile_index:(datafile_index+num_images)]\n",
        "\n",
        "    #for batch size of 400 (augmented), need 10 images\n",
        "    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        data_batch[count,:] = row.split()\n",
        "        count += 1\n",
        "\n",
        "    #separate label and input:\n",
        "    input_batch_flat = np.array(data_batch[:,:12100], dtype=int)\n",
        "    label_batch = np.array(data_batch[:,-1])\n",
        "\n",
        "    #convert input batch back to a 2D array:\n",
        "    input_batch = np.empty((110,110,np.shape(input_batch_flat)[0]), dtype=int)\n",
        "    for ii in range(np.shape(input_batch_flat)[0]):\n",
        "        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n",
        "\n",
        "\n",
        "    #convert label batch into into 1D vector: \n",
        "    #E=0, S0=1, Sp=2, Irr+Misc=3\n",
        "    #ex: label = [0,0,1,0] ==> Sp galagy\n",
        "    arr_label_batch = np.empty((np.shape(label_batch)[0],4), dtype=int)\n",
        "    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n",
        "    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n",
        "    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n",
        "    arr_label_batch[:,3] = np.array([label_batch == 'Irr+Misc'], dtype=int)\n",
        "\n",
        "    #test with image plotted\n",
        "    #import matplotlib.pyplot as plt\n",
        "    #plt.imshow(input_batch[:,:,0])\n",
        "    #plt.show()\n",
        "\n",
        "    #NOW AUGMENT THE BATCH (40X more):\n",
        "    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*40), dtype=int)\n",
        "    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*40, 4), dtype=int)\n",
        "\n",
        "    count = 0\n",
        "    for ll in range(np.shape(input_batch)[2]):\n",
        "        #Crop 5X more image (100X100 pixels)\n",
        "        C1 = input_batch[:100,:100,ll]\n",
        "        C2 = input_batch[10:,:100,ll]\n",
        "        C3 = input_batch[:100,10:,ll]\n",
        "        C4 = input_batch[10:,10:,ll]\n",
        "        C5 = input_batch[5:105,5:105,ll]\n",
        "\n",
        "        C = [C1, C2, C3, C4, C5]\n",
        "\n",
        "        for kk in range(5):\n",
        "            #Rotate 4X more image (by 90 deg)\n",
        "            for jj in range(4):\n",
        "                C_R = np.rot90(C[kk], k=jj)\n",
        "                input_batch_aug[:,:,count] = C_R\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "                \n",
        "                input_batch_aug[:,:,count] = np.swapaxes(C_R,0,1)\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "\n",
        "\n",
        "    #PUT THE DATA AS A PYTORCH TENSOR:\n",
        "    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n",
        "    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n",
        "    \n",
        "    return tensor_input_batch_aug, tensor_label_batch_aug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "IwHOD5tMmHWN",
        "outputId": "56e8a28c-1e66-4d57-be19-88b35170a799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-1a0bdaaad7e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Use this loop for training over entire dataset at each epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrand_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;31m#print(np.shape(image_batch), np.shape(label_batch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-ef3ce24bbf8c>\u001b[0m in \u001b[0;36mdata_batch\u001b[0;34m(datafile_index, num_images, data_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0minput_batch_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_R\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0marr_label_batch_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr_label_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Use function defined above:\n",
        "#rand_index = np.random.permutation(1403)\n",
        "#rand_index = np.random.permutation(701)\n",
        "rand_index = np.random.permutation(280)\n",
        "#rand_index = np.random.permutation(140)\n",
        "#shuffled numbers from 0 to 1402 (inclusive)\n",
        "#goes up to 14,030 images, last 4 images load separatly or just ignore\n",
        "#the random index goes up in steps of 10 in the function so randomizes the batching by selected groups of 10 images together\n",
        "\n",
        "#Use this loop for training over entire dataset at each epochs\n",
        "for ii in range(np.shape(rand_index)[0]):\n",
        "  image_batch, label_batch = data_batch(datafile_index=50*rand_index[ii], num_images=50)\n",
        "  #print(np.shape(image_batch), np.shape(label_batch))\n",
        "  #print(ii)\n",
        "\n",
        "#TAKES 40 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 10 IMAGES (400 when augmented)\n",
        "#TAKES 21 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 20 IMAGES (800 when augmented)\n",
        "#TAKES 12 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 50 IMAGES (2000 when augmented)\n",
        "#TAKES 8 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 100 IMAGES (4000 when augmented)\n",
        "\n",
        "#USE 50 images for 12 MIN, good compromise for small enough batches and fast enoguh loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPg40lr6LigH"
      },
      "outputs": [],
      "source": [
        "#Train and test set:\n",
        "rand_index = np.random.permutation(280)\n",
        "\n",
        "rand_train = rand_index[:200]\n",
        "rand_test = rand_index[200:]\n",
        "\n",
        "#Use this loop for training over entire dataset at each epochs\n",
        "for ii in range(np.shape(rand_train)[0]):\n",
        "  image_batch, label_batch = data_batch(datafile_index=50*rand_train[ii], num_images=50)\n",
        "\n",
        "for ii in range(np.shape(rand_test)[0]):\n",
        "  image_batch, label_batch = data_batch(datafile_index=50*rand_test[ii], num_images=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz1elmCrb96S"
      },
      "source": [
        "##Less Data Augmentation (only Cropping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "FeZhlRxXM8sX",
        "outputId": "a9d63118-c788-4351-be69-5cd596381f32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 100, 50])\n",
            "torch.Size([100, 100, 50])\n",
            "torch.Size([100, 100, 50])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1822adc8898a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#Use this loop for training over entire dataset at each epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch_aug5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrand_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;31m#print(np.shape(label_batch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1822adc8898a>\u001b[0m in \u001b[0;36mdata_batch_aug5\u001b[0;34m(datafile_index, num_images, data_file)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#Take batch of num_images rows from datafile:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#for batch size of 400 (augmented), need 10 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#LESS DATA AUGMENTION: crop only = X5 augmentation:\n",
        "\n",
        "#AUGMENT ONLY X5 (ONLY BY CROPPING)\n",
        "def data_batch_aug5(datafile_index, num_images=10, data_file='/content/drive/MyDrive/data/data_g_band.txt'):\n",
        "    '''\n",
        "    Description:\n",
        "        Access datafile.txt, each row is flattened 110x110 image + 1 label string (E, Sp, S0, Irr+Misc).\n",
        "        Returns an augmented batch of num_images X 5.\n",
        "        The labels are converted to 1D vectors (ex: Sp = [0,0,1,0])\n",
        "        Need to give a datafile_index that tells which rows to pick.\n",
        "    Inputs:\n",
        "        datafile_index: index of row in datafile to load. loads rows datafile_index to datafile_index+num_images.\n",
        "        num_images: number of different images to load per batch, total batch size \n",
        "        is 5 X num_images. (default: 10 (for 5X10 = 400 batch size like in paper)\n",
        "        data_file: datafile full path, need to add shortcut to local Drive. (default: '/content/drive/MyDrive/data/data_g_band.txt')\n",
        "    Outputs:\n",
        "        tensor_input_batch_aug: dimensions: (100, 100, num_images X 5). \n",
        "        tensor_label_batch_aug: dimensions: (num_images X 5, 4)\n",
        "    '''\n",
        "\n",
        "    #data_file = 'data_g_band.txt'\n",
        "\n",
        "    #Take batch of num_images rows from datafile:\n",
        "    with open(data_file, 'r') as f:\n",
        "        rows = f.readlines()[datafile_index:(datafile_index+num_images)]\n",
        "\n",
        "    #for batch size of 400 (augmented), need 10 images\n",
        "    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        data_batch[count,:] = row.split()\n",
        "        count += 1\n",
        "\n",
        "    #separate label and input:\n",
        "    input_batch_flat = np.array(data_batch[:,:12100], dtype=int)\n",
        "    label_batch = np.array(data_batch[:,-1])\n",
        "\n",
        "    #convert input batch back to a 2D array:\n",
        "    input_batch = np.empty((110,110,np.shape(input_batch_flat)[0]), dtype=int)\n",
        "    for ii in range(np.shape(input_batch_flat)[0]):\n",
        "        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n",
        "\n",
        "\n",
        "    #convert label batch into into 1D vector: \n",
        "    #E=0, S0=1, Sp=2, Irr+Misc=3\n",
        "    #ex: label = [0,0,1,0] ==> Sp galagy\n",
        "    arr_label_batch = np.empty((np.shape(label_batch)[0],4), dtype=int)\n",
        "    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n",
        "    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n",
        "    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n",
        "    arr_label_batch[:,3] = np.array([label_batch == 'Irr+Misc'], dtype=int)\n",
        "\n",
        "    #test with image plotted\n",
        "    #import matplotlib.pyplot as plt\n",
        "    #plt.imshow(input_batch[:,:,0])\n",
        "    #plt.show()\n",
        "\n",
        "    #NOW AUGMENT THE BATCH (5X more):\n",
        "    how_much_augment = 5\n",
        "    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*how_much_augment), dtype=int)\n",
        "    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*how_much_augment, 4), dtype=int)\n",
        "\n",
        "    count = 0\n",
        "    for ll in range(np.shape(input_batch)[2]):\n",
        "        #Crop 5X more image (100X100 pixels)\n",
        "        C1 = input_batch[:100,:100,ll]\n",
        "        C2 = input_batch[10:,:100,ll]\n",
        "        C3 = input_batch[:100,10:,ll]\n",
        "        C4 = input_batch[10:,10:,ll]\n",
        "        C5 = input_batch[5:105,5:105,ll]\n",
        "\n",
        "        C = [C1, C2, C3, C4, C5]\n",
        "\n",
        "        for kk in range(5):\n",
        "            input_batch_aug[:,:,count] = C[kk]\n",
        "            arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "            count += 1\n",
        "\n",
        "    #PUT THE DATA AS A PYTORCH TENSOR:\n",
        "    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n",
        "    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n",
        "    \n",
        "    return tensor_input_batch_aug, tensor_label_batch_aug\n",
        "\n",
        "\n",
        "#Test above function:\n",
        "rand_index = np.random.permutation(1403) #10 images\n",
        "rand_train = rand_index[:200] #arbitrary values\n",
        "rand_test = rand_index[200:]\n",
        "\n",
        "#Use this loop for training over entire dataset at each epochs\n",
        "for ii in range(np.shape(rand_train)[0]):\n",
        "  image_batch, label_batch = data_batch_aug5(datafile_index=10*rand_train[ii], num_images=10)\n",
        "  print(np.shape(image_batch))\n",
        "  #print(np.shape(label_batch))\n",
        "  #print(label_batch)\n",
        "  #Check: 10 images X 5 augmentation = 100 x 100 x 50 tensor size\n",
        "  #check: label size is 10 x 5 = 50 x 4 (4 labels)\n",
        "  #check: label is 5 type in a row then another 5 in a row etc ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpaffLfHcDvr"
      },
      "source": [
        "##Data Augmentation for 3 Way Classification (not 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GjWvOLeVmGMQ",
        "outputId": "6e25cc68-5889-43ca-c74c-759218ab7e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n",
            "torch.Size([100, 100, 400]) torch.Size([400, 3])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e367320ac064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m   \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_batch_3_way\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrand_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-e367320ac064>\u001b[0m in \u001b[0;36mdata_batch_3_way\u001b[0;34m(datafile_index, num_images, data_file)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Take batch of num_images rows from datafile:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#for batch size of 400 (augmented), need 10 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Now with indexes of irregulars to skip, load 3 way classified data:\n",
        "\n",
        "#LOAD THE DATA FROM TXT FILE INTO A BATCH:\n",
        "def data_batch_3_way(datafile_index, num_images=10, data_file='/content/drive/MyDrive/data/data_g_band_3way.txt'):\n",
        "    '''\n",
        "    Description:\n",
        "      3 way classifier data loader\n",
        "    '''\n",
        "\n",
        "    #Take batch of num_images rows from datafile:\n",
        "    with open(data_file, 'r') as f:\n",
        "        rows = f.readlines()[datafile_index:(datafile_index+num_images)]\n",
        "\n",
        "    #for batch size of 400 (augmented), need 10 images\n",
        "    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        data_batch[count,:] = row.split()\n",
        "        count += 1\n",
        "\n",
        "    #separate label and input:\n",
        "    input_batch_flat = np.array(data_batch[:,:12100], dtype=int)\n",
        "    label_batch = np.array(data_batch[:,-1])\n",
        "\n",
        "    #convert input batch back to a 2D array:\n",
        "    input_batch = np.empty((110,110,np.shape(input_batch_flat)[0]), dtype=int)\n",
        "    for ii in range(np.shape(input_batch_flat)[0]):\n",
        "        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n",
        "\n",
        "\n",
        "    #convert label batch into into 1D vector: \n",
        "    #E=0, S0=1, Sp=2, Irr+Misc=3\n",
        "    #ex: label = [0,0,1,0] ==> Sp galagy\n",
        "    arr_label_batch = np.empty((np.shape(label_batch)[0],3), dtype=int)\n",
        "    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n",
        "    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n",
        "    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n",
        "    \n",
        "    #test with image plotted\n",
        "    #import matplotlib.pyplot as plt\n",
        "    #plt.imshow(input_batch[:,:,0])\n",
        "    #plt.show()\n",
        "\n",
        "    #NOW AUGMENT THE BATCH (40X more):\n",
        "    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*40), dtype=int)\n",
        "    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*40, 3), dtype=int)\n",
        "\n",
        "    count = 0\n",
        "    for ll in range(np.shape(input_batch)[2]):\n",
        "        #Crop 5X more image (100X100 pixels)\n",
        "        C1 = input_batch[:100,:100,ll]\n",
        "        C2 = input_batch[10:,:100,ll]\n",
        "        C3 = input_batch[:100,10:,ll]\n",
        "        C4 = input_batch[10:,10:,ll]\n",
        "        C5 = input_batch[5:105,5:105,ll]\n",
        "\n",
        "        C = [C1, C2, C3, C4, C5]\n",
        "\n",
        "        for kk in range(5):\n",
        "            #Rotate 4X more image (by 90 deg)\n",
        "            for jj in range(4):\n",
        "                C_R = np.rot90(C[kk], k=jj)\n",
        "                input_batch_aug[:,:,count] = C_R\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "                \n",
        "                input_batch_aug[:,:,count] = np.swapaxes(C_R,0,1)\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "\n",
        "\n",
        "    #PUT THE DATA AS A PYTORCH TENSOR:\n",
        "    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n",
        "    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n",
        "    \n",
        "    return tensor_input_batch_aug, tensor_label_batch_aug\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Train and test set:\n",
        "rand_index = np.random.permutation(1360) #10 images #NOTE: 3 way ==> 1360, NOT 1403\n",
        "rand_train = rand_index[:200]\n",
        "rand_test = rand_index[200:]\n",
        "\n",
        "#Use this loop for training over entire dataset at each epochs\n",
        "\n",
        "for ii in range(np.shape(rand_train)[0]):\n",
        "  image_batch, label_batch = data_batch_3_way(datafile_index=10*rand_train[ii], num_images=10)\n",
        "  print(np.shape(image_batch), np.shape(label_batch))\n",
        "\n",
        "for ii in range(np.shape(rand_test)[0]):\n",
        "  image_batch, label_batch = data_batch(datafile_index=10*rand_test[ii], num_images=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC_IoFCftJyw"
      },
      "outputs": [],
      "source": [
        "#Load All the data into into one large 'batch':\n",
        "\n",
        "#LOAD THE DATA FROM TXT FILE INTO A BATCH:\n",
        "def data_load_only_images(num_images=3, data_file='/content/drive/MyDrive/data/data_g_band.txt'):\n",
        "    \n",
        "    with open(data_file, 'r') as f:\n",
        "        rows = f.readlines()[0:num_images]\n",
        "\n",
        "    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        data_batch[count,:] = row.split()\n",
        "        count += 1\n",
        "\n",
        "    #separate label and input:\n",
        "    input_batch_flat = np.array(data_batch[:,:12100], dtype=int)\n",
        "    label_batch = np.array(data_batch[:,-1])\n",
        "\n",
        "    #convert input batch back to a 2D array:\n",
        "    input_batch = np.empty((110,110,np.shape(input_batch_flat)[0]), dtype=int)\n",
        "    for ii in range(np.shape(input_batch_flat)[0]):\n",
        "        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n",
        "\n",
        "\n",
        "    #convert label batch into into 1D vector: \n",
        "    #E=0, S0=1, Sp=2, Irr+Misc=3\n",
        "    #ex: label = [0,0,1,0] ==> Sp galagy\n",
        "    arr_label_batch = np.empty((np.shape(label_batch)[0],4), dtype=int)\n",
        "    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n",
        "    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n",
        "    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n",
        "    arr_label_batch[:,3] = np.array([label_batch == 'Irr+Misc'], dtype=int)\n",
        "\n",
        "    #test with image plotted\n",
        "    #import matplotlib.pyplot as plt\n",
        "    #plt.imshow(input_batch[:,:,0])\n",
        "    #plt.show()\n",
        "\n",
        "    #NOW AUGMENT THE BATCH (40X more):\n",
        "    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*40), dtype=int)\n",
        "    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*40, 4), dtype=int)\n",
        "\n",
        "    count = 0\n",
        "    for ll in range(np.shape(input_batch)[2]):\n",
        "        #Crop 5X more image (100X100 pixels)\n",
        "        C1 = input_batch[:100,:100,ll]\n",
        "        C2 = input_batch[10:,:100,ll]\n",
        "        C3 = input_batch[:100,10:,ll]\n",
        "        C4 = input_batch[10:,10:,ll]\n",
        "        C5 = input_batch[5:105,5:105,ll]\n",
        "\n",
        "        C = [C1, C2, C3, C4, C5]\n",
        "\n",
        "        for kk in range(5):\n",
        "            #Rotate 4X more image (by 90 deg)\n",
        "            for jj in range(4):\n",
        "                C_R = np.rot90(C[kk], k=jj)\n",
        "                input_batch_aug[:,:,count] = C_R\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "                \n",
        "                input_batch_aug[:,:,count] = np.swapaxes(C_R,0,1)\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "\n",
        "\n",
        "    #PUT THE DATA AS A PYTORCH TENSOR:\n",
        "    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n",
        "    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n",
        "    \n",
        "    return tensor_input_batch_aug, tensor_label_batch_aug\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "f8696d3d898bc62b90f4cd7d878fc87a051ec77bbff0b42338ab50969b9d3714"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
