{"cells":[{"cell_type":"markdown","metadata":{"id":"oQfh4ENuykfl"},"source":["# **PHYS 449: Final Project Notebook**\n","#### Reproducing results from \"Morphological classification of galaxies with deep learning: comparing 3-way and 4-way CNNs\" by Mitchell K. Cavanagh, Kenji Bekki and Brent A. Groves\n","\n","*This all just assumed 4-way classification for now"]},{"cell_type":"markdown","metadata":{"id":"q-Ma_H5RnGtI"},"source":["# **Set Current Working Directory**\n","\n","For example, for Ashley this is:\n","\n","'/content/drive/MyDrive/Fall 2022/PHYS 449/Final Project'"]},{"cell_type":"code","execution_count":196,"metadata":{"executionInfo":{"elapsed":166,"status":"ok","timestamp":1670195329738,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"7JMBwDQ4nV8N"},"outputs":[],"source":["##CWD = '/content/drive/MyDrive/Fall 2022/PHYS 449/Final Project/'"]},{"cell_type":"code","execution_count":197,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":744,"status":"ok","timestamp":1670195330655,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"Aa8SwGc2rpn1","outputId":"7e633411-9619-4090-f61b-a2ed5e40342d"},"outputs":[],"source":["##from google.colab import drive\n","##drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"FvlSR1N2ykL9"},"source":["# **Import Packages**\n","\n","Begin by importing all the needed packages"]},{"cell_type":"code","execution_count":198,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1670195330656,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"orwxGi_hFK2v"},"outputs":[],"source":["# run the pip install if you don't have wandb\n","#! pip install wandb==0.9.7\n","#! wandb login\n","# if it asks you for a code you can use: 469092e605208488a82954d1b80c92028151663a"]},{"cell_type":"code","execution_count":199,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1670195330657,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"FnQlrR-O-Jmh"},"outputs":[],"source":["from keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from tqdm import tqdm\n","import os"]},{"cell_type":"code","execution_count":200,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1670195330659,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"K4vEKvAuJDPC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files in 'c:\\\\Users\\\\alexc\\\\OneDrive\\\\Desktop\\\\Phys 449\\\\Final_Project\\\\PHYS449_FinalProject': ['.git', '.gitignore', 'C1_C2_Implementation.py', 'C1_Implementation.py', 'C2_Implementation.py', 'data', 'documents', 'final_saved_models', 'main.py', 'networks', 'notebooks', 'presentations', 'PyTorch_CNN_4way_TrainTest_Outline.ipynb', 'README.md', 'saved_results', 'src']\n"]}],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torchvision import transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","import wandb\n","import time\n","\n","\n","cwd = os.getcwd()  # Get the current working directory (cwd)\n","files = os.listdir(cwd)  # Get all the files in that directory\n","print(\"Files in %r: %s\" % (cwd, files))\n","\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"Va-_oVtsykW4"},"source":["# **Define Network Structure**\n","We are considering two 2D CNNs, C1 and C2, which are described in the paper and outlined below\n","- forgot to add batch norm first time"]},{"cell_type":"code","execution_count":201,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1670195330660,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"TtWL4NQip11I"},"outputs":[],"source":["num_classes = 4"]},{"cell_type":"code","execution_count":202,"metadata":{"executionInfo":{"elapsed":202,"status":"ok","timestamp":1670195330849,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"ZOk2Z6iXJF1y"},"outputs":[],"source":["# need to double check but this is roughly right\n","networkc1 = nn.Sequential(\n","    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=0),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(32),\n","    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=0),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(64),\n","    # max pool here\n","    nn.MaxPool2d(kernel_size=2),\n","    nn.Flatten(),\n","    #nn.Linear(135424, 256), \n","    # dropout here\n","    nn.Dropout(0.5),\n","    nn.ReLU(), # do we need an activation function here?\n","    nn.Linear(135424,256),\n","    nn.ReLU(),\n","    nn.Linear(256, num_classes))"]},{"cell_type":"code","execution_count":203,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1670195331029,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"JetZ8Dimne4H"},"outputs":[],"source":["networkc2 = nn.Sequential(\n","    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=7, stride=1, padding=0),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(32),\n","    nn.MaxPool2d(kernel_size=2),\n","\n","    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=0),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(64),\n","\n","    nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=0),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(64),\n","    nn.MaxPool2d(kernel_size=2),\n","\n","    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0),\n","    nn.ReLU(),\n","    nn.BatchNorm2d(128),\n","    nn.MaxPool2d(kernel_size=2),\n","\n","    nn.Flatten(),\n","    nn.Linear(8192, 256),\n","    nn.Dropout(0.5),\n","\n","    nn.ReLU(),\n","    nn.Linear(256,256),\n","    nn.ReLU(),\n","    nn.Linear(256, num_classes))"]},{"cell_type":"markdown","metadata":{"id":"04iju2Sqm-2W"},"source":["https://stackoverflow.com/questions/66626700/difference-between-tensorflows-tf-keras-layers-dense-and-pytorchs-torch-nn-lin#:~:text=Within%20PyTorch%2C%20a%20Linear%20(or,Linear%20layer%20(see%20here)."]},{"cell_type":"markdown","metadata":{"id":"PyB4yRaICITu"},"source":["# **Load Data**"]},{"cell_type":"code","execution_count":204,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1670195331729,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"RjvEFjidIlKu","outputId":"648d5f70-518f-4093-92f8-5f4e3bbfc6e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\alexc\\OneDrive\\Desktop\\Phys 449\\Final_Project\\PHYS449_FinalProject\\PyTorch_CNN_4way_TrainTest_Outline.ipynb\n"]}],"source":["#Import google drive (need to put data folder as shortcut in your local drive My Drive):\n","##from google.colab import drive\n","##drive.mount('/content/drive')\n","\n","print(os.path.abspath('PyTorch_CNN_4way_TrainTest_Outline.ipynb'))\n"]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[],"source":["#LOAD THE DATA FROM TXT FILE INTO A BATCH:\n","def data_batch(datafile_index, num_images=10, data_file=\"/data/data_g_band.txt\", plotting=False):\n","    '''\n","    Description:\n","        Access datafile.txt, each row is flattened 110x110 image + 1 label string (E, Sp, S0, Irr+Misc).\n","        Returns an augmented batch of num_images X 40.\n","        The labels are converted to 1D vectors (ex: Sp = [0,0,1,0])\n","        Need to give a datafile_index that tells which rows to pick.\n","    Inputs:\n","        datafile_index: index of row in datafile to load. loads rows datafile_index to datafile_index+num_images.\n","        num_images: number of different images to load per batch, total batch size \n","        is 40 X num_images. (default: 10 (for 40X10 = 400 batch size like in paper)\n","        data_file: datafile full path, need to add shortcut to local Drive. (default: '/content/drive/MyDrive/data/data_g_band.txt')\n","    Outputs:\n","        tensor_input_batch_aug: dimensions: (100, 100, num_images X 40). \n","        tensor_label_batch_aug: dimensions: (num_images X 40, 4)\n","    '''\n","\n","    #Take batch of num_images rows from datafile:\n","    with open(data_file, 'r') as f:\n","        rows = f.readlines()[datafile_index:(datafile_index+num_images)]\n","\n","    #for batch size of 400 (augmented), need 10 images\n","    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n","    count = 0\n","    for row in rows:\n","        data_batch[count,:] = row.split()\n","        count += 1\n","\n","    #separate label and input:\n","    input_batch_flat = np.array(data_batch[:,:12100], dtype=float)#, dtype=int)\n","    label_batch = np.array(data_batch[:,-1])\n","\n","    #convert input batch back to a 2D array:\n","    input_batch = np.zeros((110,110,np.shape(input_batch_flat)[0]))#, dtype=int)\n","    for ii in range(np.shape(input_batch_flat)[0]):\n","        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n","\n","\n","    #convert label batch into into 1D vector: \n","    #E=0, S0=1, Sp=2, Irr+Misc=3\n","    #ex: label = [0,0,1,0] ==> Sp galagy\n","    arr_label_batch = np.zeros((np.shape(label_batch)[0],4), dtype=int)\n","    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n","    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n","    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n","    arr_label_batch[:,3] = np.array([label_batch == 'Irr+Misc'], dtype=int)\n","\n","    if plotting == True:\n","      #test with image plotted\n","      plt.imshow(input_batch[:,:,0])\n","      plt.show()\n","\n","    #NOW AUGMENT THE BATCH (40X more):\n","    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*40), dtype=int)\n","    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*40, 4), dtype=int)\n","\n","    count = 0\n","    for ll in range(np.shape(input_batch)[2]):\n","        #Crop 5X more image (100X100 pixels)\n","        C1 = input_batch[:100,:100,ll]\n","        C2 = input_batch[10:,:100,ll]\n","        C3 = input_batch[:100,10:,ll]\n","        C4 = input_batch[10:,10:,ll]\n","        C5 = input_batch[5:105,5:105,ll]\n","\n","        C = [C1, C2, C3, C4, C5]\n","\n","        for kk in range(5):\n","            #Rotate 4X more image (by 90 deg)\n","            for jj in range(4):\n","                C_R = np.rot90(C[kk], k=jj)\n","                input_batch_aug[:,:,count] = C_R\n","                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n","                count += 1\n","                \n","                input_batch_aug[:,:,count] = np.swapaxes(C_R,0,1)\n","                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n","                count += 1\n","\n","\n","    #PUT THE DATA AS A PYTORCH TENSOR:\n","    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n","    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n","    \n","    return tensor_input_batch_aug, tensor_label_batch_aug"]},{"cell_type":"code","execution_count":206,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1670195331731,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"k1xzMlpkQjN2","outputId":"e866bc2e-9de7-43dc-e3d2-2f8e13bcfc50"},"outputs":[{"data":{"text/plain":["'\\n#Test above function:\\nrand_index = np.random.permutation(1403) #10 images\\nrand_train = rand_index[:200] #arbitrary values\\nrand_test = rand_index[200:]\\n\\n#Use this loop for training over entire dataset at each epochs\\nfor ii in range(np.shape(rand_train)[0]):\\n  image_batch, label_batch = data_batch_aug5(datafile_index=10*rand_train[ii], num_images=10)\\n  ##print(np.shape(image_batch))\\n  ##print(np.shape(label_batch))\\n  ##print(label_batch)\\n  #Check: 10 images X 5 augmentation = 100 x 100 x 50 tensor size\\n  #check: label size is 10 x 5 = 50 x 4 (4 labels)\\n  #check: label is 5 type in a row then another 5 in a row etc ...\\n'"]},"execution_count":206,"metadata":{},"output_type":"execute_result"}],"source":["#LESS DATA AUGMENTION: crop only = X5 augmentation:\n","\n","#AUGMENT ONLY X5 (ONLY BY CROPPING)\n","def data_batch_aug5(datafile_index, num_images=10,  data_file=\"/data/data_g_band.txt\", plotting=False):\n","    '''\n","    Description:\n","        Access datafile.txt, each row is flattened 110x110 image + 1 label string (E, Sp, S0, Irr+Misc).\n","        Returns an augmented batch of num_images X 5.\n","        The labels are converted to 1D vectors (ex: Sp = [0,0,1,0])\n","        Need to give a datafile_index that tells which rows to pick.\n","    Inputs:\n","        datafile_index: index of row in datafile to load. loads rows datafile_index to datafile_index+num_images.\n","        num_images: number of different images to load per batch, total batch size \n","        is 5 X num_images. (default: 10 (for 5X10 = 400 batch size like in paper)\n","        data_file: datafile full path, need to add shortcut to local Drive. (default: '/content/drive/MyDrive/data/data_g_band.txt')\n","    Outputs:\n","        tensor_input_batch_aug: dimensions: (100, 100, num_images X 5). \n","        tensor_label_batch_aug: dimensions: (num_images X 5, 4)\n","    '''\n","\n","    #data_file = 'data_g_band.txt'\n","\n","    #Take batch of num_images rows from datafile:\n","    with open(data_file, 'r') as f:\n","        rows = f.readlines()[datafile_index:(datafile_index+num_images)]\n","\n","    #for batch size of 400 (augmented), need 10 images\n","    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n","    count = 0\n","    for row in rows:\n","        data_batch[count,:] = row.split()\n","        count += 1\n","\n","    #separate label and input:\n","    input_batch_flat = np.array(data_batch[:,:12100], dtype=int)\n","    label_batch = np.array(data_batch[:,-1])\n","\n","    #convert input batch back to a 2D array:\n","    input_batch = np.empty((110,110,np.shape(input_batch_flat)[0]), dtype=int)\n","    for ii in range(np.shape(input_batch_flat)[0]):\n","        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n","\n","\n","    #convert label batch into into 1D vector: \n","    #E=0, S0=1, Sp=2, Irr+Misc=3\n","    #ex: label = [0,0,1,0] ==> Sp galagy\n","    arr_label_batch = np.empty((np.shape(label_batch)[0],4), dtype=int)\n","    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n","    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n","    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n","    arr_label_batch[:,3] = np.array([label_batch == 'Irr+Misc'], dtype=int)\n","\n","    #test with image plotted\n","    if plotting == True:\n","      plt.imshow(input_batch[:,:,0])\n","      plt.show()\n","\n","    #NOW AUGMENT THE BATCH (5X more):\n","    how_much_augment = 5\n","    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*how_much_augment), dtype=int)\n","    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*how_much_augment, 4), dtype=int)\n","\n","    count = 0\n","    for ll in range(np.shape(input_batch)[2]):\n","        #Crop 5X more image (100X100 pixels)\n","        C1 = input_batch[:100,:100,ll]\n","        C2 = input_batch[10:,:100,ll]\n","        C3 = input_batch[:100,10:,ll]\n","        C4 = input_batch[10:,10:,ll]\n","        C5 = input_batch[5:105,5:105,ll]\n","\n","        C = [C1, C2, C3, C4, C5]\n","\n","        for kk in range(5):\n","            input_batch_aug[:,:,count] = C[kk]\n","            arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n","            count += 1\n","\n","    #PUT THE DATA AS A PYTORCH TENSOR:\n","    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n","    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n","    \n","    return tensor_input_batch_aug, tensor_label_batch_aug\n","\n","'''\n","#Test above function:\n","rand_index = np.random.permutation(1403) #10 images\n","rand_train = rand_index[:200] #arbitrary values\n","rand_test = rand_index[200:]\n","\n","#Use this loop for training over entire dataset at each epochs\n","for ii in range(np.shape(rand_train)[0]):\n","  image_batch, label_batch = data_batch_aug5(datafile_index=10*rand_train[ii], num_images=10)\n","  ##print(np.shape(image_batch))\n","  ##print(np.shape(label_batch))\n","  ##print(label_batch)\n","  #Check: 10 images X 5 augmentation = 100 x 100 x 50 tensor size\n","  #check: label size is 10 x 5 = 50 x 4 (4 labels)\n","  #check: label is 5 type in a row then another 5 in a row etc ...\n","'''"]},{"cell_type":"code","execution_count":207,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1670195331731,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"ktUQRMpu-RBS","outputId":"91b7d3cf-7134-4a98-b6a2-a800d42e1be7"},"outputs":[{"data":{"text/plain":["'\\nrand_index = np.random.permutation(280)\\n\\nprint(np.shape(rand_index)[0])\\n\\n#Use this loop for training over entire dataset at each epochs\\nfor ii in range(np.shape(rand_index)[0]):\\n  image_batch, label_batch = data_batch(datafile_index=50*rand_index[ii], num_images=50)\\n  #print(np.shape(image_batch), np.shape(label_batch))\\n  #print(ii)\\n'"]},"execution_count":207,"metadata":{},"output_type":"execute_result"}],"source":["# ashley's troubleshooting\n","'''\n","rand_index = np.random.permutation(280)\n","\n","print(np.shape(rand_index)[0])\n","\n","#Use this loop for training over entire dataset at each epochs\n","for ii in range(np.shape(rand_index)[0]):\n","  image_batch, label_batch = data_batch(datafile_index=50*rand_index[ii], num_images=50)\n","  #print(np.shape(image_batch), np.shape(label_batch))\n","  #print(ii)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"P6yVoN5dCUtN"},"source":["# **Sample Data**\n","Here we check that the data files are how we expect them to be"]},{"cell_type":"code","execution_count":208,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"executionInfo":{"elapsed":1907,"status":"ok","timestamp":1670195333625,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"n2yn5gPM-0_w","outputId":"326096ee-624c-4c8f-e10a-4bf40ff2895e"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]},{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/data/data_g_band.txt'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[208], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mshape(rand_index)[\u001b[39m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m ii \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39mshape(rand_index)[\u001b[39m0\u001b[39m]):\n\u001b[1;32m----> 5\u001b[0m   image_batch, label_batch \u001b[39m=\u001b[39m data_batch(datafile_index\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m\u001b[39m*\u001b[39;49mrand_index[ii], num_images\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, plotting \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n","Cell \u001b[1;32mIn[205], line 20\u001b[0m, in \u001b[0;36mdata_batch\u001b[1;34m(datafile_index, num_images, data_file, plotting)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mDescription:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m    Access datafile.txt, each row is flattened 110x110 image + 1 label string (E, Sp, S0, Irr+Misc).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m    tensor_label_batch_aug: dimensions: (num_images X 40, 4)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m#Take batch of num_images rows from datafile:\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(data_file, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     21\u001b[0m     rows \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()[datafile_index:(datafile_index\u001b[39m+\u001b[39mnum_images)]\n\u001b[0;32m     23\u001b[0m \u001b[39m#for batch size of 400 (augmented), need 10 images\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/data_g_band.txt'"]}],"source":["# can just call data load for some if we made plotting an optional arg\n","rand_index = np.random.permutation(1)#10)\n","print(np.shape(rand_index)[0])\n","for ii in range(np.shape(rand_index)[0]):\n","  image_batch, label_batch = data_batch(datafile_index=50*rand_index[ii], num_images=50, plotting = True)"]},{"cell_type":"markdown","metadata":{"id":"m9eaQI4kCbVT"},"source":["# **Split Data**\n","Here we split data into trainng, testing datasets (validation split will be done by keras during training)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1670195333626,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"qj1M9LgXI5_R"},"outputs":[],"source":["#Train and test set\n","num_images = 50\n","dataset_size = int(14030/num_images) # WHENEVER YOU SEE THIS LESS THAN 1403 IT'S ARTIFIFICALLY SMALL JUST TO TROUBLESHOOT CODE AND SHOULD NOT BE USED TO TRAIN\n","train_split = 0.7\n","test_valid_split = 0.5 # X\n","test_split = 1 - train_split\n","split_cutoff = int(dataset_size*train_split)\n","\n","rand_index = np.random.permutation(dataset_size)\n","rand_train = rand_index[:split_cutoff] # get these split like paper proportions\n","rand_test = rand_index[split_cutoff:dataset_size] # valudation will be taken from test set"]},{"cell_type":"markdown","metadata":{"id":"Un1x2W4GAMex"},"source":["# **Training**\n","Ideally we use seperate notebooks to train each one\n","\n","C2 uses Adam, wheras C1 uses Adadelta: \n","\n","  https://www.aanda.org/articles/aa/full_html/2020/09/aa37963-20/aa37963-20.html\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1670195333627,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"5cu8-Z52PSNH"},"outputs":[],"source":["network_to_train = 'C2'\n","\n","# define hyperparameters of training\n","if network_to_train == 'C1':\n","  n_epochs = 12\n","  # can't find learning rate mentioned so I'm leaving it as default for now\n","  cn_model = networkc1\n","  #optimizer = torch.optim.Adadelta(cn_model.parameters()))\n","  # trying adam for a sec\n","  optimizer = torch.optim.Adam(cn_model.parameters(), lr=2e-4)\n","\n","elif network_to_train == 'C2':\n","  n_epochs = 20\n","  cn_model = networkc2\n","  lr = 2*pow(10,-4)\n","  optimizer = torch.optim.Adam(cn_model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":2598,"status":"ok","timestamp":1670195336214,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"LkSNC_OfKI5x","outputId":"0bec60a0-8a5e-4ca5-e543-3102a8a09f24"},"outputs":[{"data":{"text/html":["\n","                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://app.wandb.ai/449-final-project/rough-trails\" target=\"_blank\">https://app.wandb.ai/449-final-project/rough-trails</a><br/>\n","                Run page: <a href=\"https://app.wandb.ai/449-final-project/rough-trails/runs/1djkeqiz\" target=\"_blank\">https://app.wandb.ai/449-final-project/rough-trails/runs/1djkeqiz</a><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.13.5 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]}],"source":["# connect to w&b for experiment tracking\n","wandb.init(project=\"rough-trails\", entity=\"449-final-project\")\n","\n","wandb.config = {\n","  \"learning_rate\": lr,\n","  \"epochs\": n_epochs,\n","  \"model\": network_to_train,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1670195336215,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"OBjUVf7Xl0t9"},"outputs":[],"source":["# define things that are the same for both notebooks\n","loss_fn = torch.nn.CrossEntropyLoss() "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1670195336217,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"pmXbguJZy2TP"},"outputs":[],"source":["# add some code here to reset weights if we run this a lot"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1670195336218,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"F_HE_24Jl4MV","outputId":"f8f85eb1-29b0-4bab-f280-800de0937faf"},"outputs":[{"data":{"text/plain":["Sequential(\n","  (0): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1))\n","  (1): ReLU()\n","  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (5): ReLU()\n","  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (7): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n","  (8): ReLU()\n","  (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (12): ReLU()\n","  (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (15): Flatten(start_dim=1, end_dim=-1)\n","  (16): Linear(in_features=8192, out_features=256, bias=True)\n","  (17): Dropout(p=0.5, inplace=False)\n","  (18): ReLU()\n","  (19): Linear(in_features=256, out_features=256, bias=True)\n","  (20): ReLU()\n","  (21): Linear(in_features=256, out_features=4, bias=True)\n",")"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize network & move to GPU\n","cn_model.to(DEVICE)  # comment out if this gives you issues"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uv3kgsvZY_LT","outputId":"9d30279a-5ac6-4a97-93e2-4db66098e3da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model initialized and prepped, begin training...\n","epoch: 1\n","train batch accuracy = 34.0 %\n","train batch accuracy = 27.6 %\n","train batch accuracy = 23.200000000000003 %\n","train batch accuracy = 24.0 %\n","train batch accuracy = 28.799999999999997 %\n","train batch accuracy = 34.4 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 34.0 %\n","train batch accuracy = 62.8 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 64.0 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 41.199999999999996 %\n","train batch accuracy = 61.6 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 45.6 %\n","train batch accuracy = 51.6 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 44.0 %\n","train batch accuracy = 41.6 %\n","train batch accuracy = 32.800000000000004 %\n","train batch accuracy = 32.0 %\n","train batch accuracy = 26.8 %\n","train batch accuracy = 35.199999999999996 %\n","train batch accuracy = 25.2 %\n","train batch accuracy = 30.4 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 30.0 %\n","train batch accuracy = 39.6 %\n","train batch accuracy = 32.4 %\n","train batch accuracy = 47.199999999999996 %\n","train batch accuracy = 56.39999999999999 %\n","train batch accuracy = 32.0 %\n","train batch accuracy = 59.199999999999996 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 44.800000000000004 %\n","train batch accuracy = 42.4 %\n","train batch accuracy = 53.6 %\n","train batch accuracy = 55.60000000000001 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 53.6 %\n","train batch accuracy = 43.6 %\n","train batch accuracy = 41.6 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 40.8 %\n","train batch accuracy = 40.400000000000006 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 35.6 %\n","train batch accuracy = 31.2 %\n","train batch accuracy = 40.0 %\n","train batch accuracy = 30.0 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 35.6 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 35.199999999999996 %\n","train batch accuracy = 38.4 %\n","train batch accuracy = 40.8 %\n","train batch accuracy = 27.6 %\n","train batch accuracy = 28.4 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 28.000000000000004 %\n","train batch accuracy = 42.8 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 37.6 %\n","train batch accuracy = 35.199999999999996 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 44.0 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 50.8 %\n","train batch accuracy = 53.6 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 56.8 %\n","train batch accuracy = 47.199999999999996 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 50.8 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 49.2 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 44.4 %\n","train batch accuracy = 55.2 %\n","train batch accuracy = 40.400000000000006 %\n","train batch accuracy = 49.2 %\n","train batch accuracy = 43.6 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 49.2 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 56.39999999999999 %\n","train batch accuracy = 50.4 %\n","train batch accuracy = 58.8 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 44.4 %\n","train batch accuracy = 49.2 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 53.6 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 51.6 %\n","train batch accuracy = 50.4 %\n","train batch accuracy = 43.6 %\n","train batch accuracy = 52.400000000000006 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 41.199999999999996 %\n","train batch accuracy = 45.6 %\n","train batch accuracy = 39.2 %\n","train batch accuracy = 52.400000000000006 %\n","train batch accuracy = 45.2 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 40.400000000000006 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 35.6 %\n","train batch accuracy = 45.2 %\n","train batch accuracy = 31.6 %\n","train batch accuracy = 42.8 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 39.6 %\n","train batch accuracy = 43.6 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 33.2 %\n","train batch accuracy = 42.0 %\n","train batch accuracy = 35.199999999999996 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 41.6 %\n","train batch accuracy = 29.2 %\n","train batch accuracy = 35.199999999999996 %\n","train batch accuracy = 35.6 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 30.8 %\n","train batch accuracy = 47.199999999999996 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 44.4 %\n","train batch accuracy = 50.8 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 44.800000000000004 %\n","train batch accuracy = 44.0 %\n","train batch accuracy = 47.199999999999996 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 56.8 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 57.599999999999994 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 56.39999999999999 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 50.4 %\n","train batch accuracy = 55.60000000000001 %\n","train batch accuracy = 40.400000000000006 %\n","train batch accuracy = 46.400000000000006 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 57.599999999999994 %\n","train batch accuracy = 54.400000000000006 %\n","train batch accuracy = 46.400000000000006 %\n","train batch accuracy = 56.39999999999999 %\n","train batch accuracy = 57.199999999999996 %\n","train batch accuracy = 54.400000000000006 %\n","train batch accuracy = 55.2 %\n","train batch accuracy = 57.599999999999994 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 59.199999999999996 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 57.199999999999996 %\n","train batch accuracy = 51.2 %\n","train batch accuracy = 51.2 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 58.8 %\n","train batch accuracy = 44.0 %\n","train batch accuracy = 58.8 %\n","train batch accuracy = 54.400000000000006 %\n","--- 1299.3382940292358 seconds ---\n","training loss: 1.621323100766357\n","training accuracy: 44.22857142857143 %\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.13.5 is available!  To upgrade, please run:\n","\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"]},{"name":"stdout","output_type":"stream","text":["validation loss: 1.191059947013855\n","Validation accuracy = 52.0 %\n","epoch: 2\n","train batch accuracy = 48.0 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 64.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 45.2 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 32.4 %\n","train batch accuracy = 34.8 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 35.199999999999996 %\n","train batch accuracy = 33.2 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 34.0 %\n","train batch accuracy = 41.199999999999996 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 37.6 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 42.8 %\n","train batch accuracy = 24.0 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 42.8 %\n","train batch accuracy = 43.6 %\n","train batch accuracy = 39.2 %\n","train batch accuracy = 41.6 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 52.400000000000006 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 40.0 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 44.0 %\n","train batch accuracy = 29.599999999999998 %\n","train batch accuracy = 56.39999999999999 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 41.199999999999996 %\n","train batch accuracy = 40.0 %\n","train batch accuracy = 51.2 %\n","train batch accuracy = 43.2 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 57.599999999999994 %\n","train batch accuracy = 52.400000000000006 %\n","train batch accuracy = 39.2 %\n","train batch accuracy = 42.0 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 44.800000000000004 %\n","train batch accuracy = 50.4 %\n","train batch accuracy = 42.0 %\n","train batch accuracy = 43.6 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 54.800000000000004 %\n","train batch accuracy = 48.8 %\n","train batch accuracy = 46.800000000000004 %\n","train batch accuracy = 58.4 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 59.599999999999994 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 54.400000000000006 %\n","train batch accuracy = 53.6 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 44.4 %\n","train batch accuracy = 57.599999999999994 %\n","train batch accuracy = 45.2 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 51.2 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 33.6 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 40.8 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 44.800000000000004 %\n","train batch accuracy = 42.0 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 41.199999999999996 %\n","train batch accuracy = 42.0 %\n","train batch accuracy = 46.400000000000006 %\n","train batch accuracy = 40.0 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 38.4 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 49.6 %\n","train batch accuracy = 46.400000000000006 %\n","train batch accuracy = 40.0 %\n","train batch accuracy = 44.0 %\n","train batch accuracy = 48.4 %\n","train batch accuracy = 39.6 %\n","train batch accuracy = 30.8 %\n","train batch accuracy = 29.2 %\n","train batch accuracy = 40.400000000000006 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 52.800000000000004 %\n","train batch accuracy = 55.2 %\n","train batch accuracy = 54.400000000000006 %\n","train batch accuracy = 63.6 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 37.6 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 70.0 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 47.599999999999994 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 64.0 %\n","train batch accuracy = 57.599999999999994 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 31.6 %\n","train batch accuracy = 20.4 %\n","train batch accuracy = 27.6 %\n","train batch accuracy = 28.000000000000004 %\n","train batch accuracy = 32.4 %\n","train batch accuracy = 37.6 %\n","train batch accuracy = 21.6 %\n","train batch accuracy = 42.4 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 26.0 %\n","train batch accuracy = 26.8 %\n","train batch accuracy = 30.8 %\n","train batch accuracy = 37.6 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 24.8 %\n","train batch accuracy = 32.0 %\n","train batch accuracy = 39.2 %\n","train batch accuracy = 37.2 %\n","train batch accuracy = 33.2 %\n","train batch accuracy = 25.2 %\n","train batch accuracy = 30.0 %\n","train batch accuracy = 28.4 %\n","train batch accuracy = 32.4 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 41.199999999999996 %\n","train batch accuracy = 21.2 %\n","train batch accuracy = 36.8 %\n","train batch accuracy = 38.800000000000004 %\n","train batch accuracy = 30.4 %\n","train batch accuracy = 31.6 %\n","train batch accuracy = 44.4 %\n","train batch accuracy = 42.4 %\n","train batch accuracy = 40.400000000000006 %\n","train batch accuracy = 35.6 %\n","train batch accuracy = 35.6 %\n","train batch accuracy = 28.799999999999997 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 33.6 %\n","train batch accuracy = 36.4 %\n","train batch accuracy = 42.8 %\n","train batch accuracy = 48.8 %\n","train batch accuracy = 51.2 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 50.4 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 59.599999999999994 %\n","train batch accuracy = 54.800000000000004 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 56.00000000000001 %\n","--- 1231.9581532478333 seconds ---\n","training loss: 1.3334457460714846\n","training accuracy: 45.37959183673471 %\n","validation loss: 1.3447357416152954\n","Validation accuracy = 52.0 %\n","epoch: 3\n","train batch accuracy = 48.0 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 60.0 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 64.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 36.0 %\n","train batch accuracy = 46.0 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 64.0 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 42.0 %\n","train batch accuracy = 68.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 50.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 57.99999999999999 %\n","train batch accuracy = 62.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 38.0 %\n","train batch accuracy = 66.0 %\n","train batch accuracy = 52.0 %\n","train batch accuracy = 51.6 %\n","train batch accuracy = 56.00000000000001 %\n","train batch accuracy = 48.0 %\n","train batch accuracy = 54.0 %\n","train batch accuracy = 70.0 %\n"]}],"source":["# For monitoring acc and losses\n","avg_epoch_acc_train = []\n","avg_epoch_acc_val = []\n","avg_epoch_losses_train = []\n","avg_epoch_losses_val = []\n","\n","batch_size = num_images*5#40 \n","\n","print('Model initialized and prepped, begin training...')\n","cn_model.train()\n","for epoch in range(n_epochs):  \n","    print('epoch:', epoch+1)\n","\n","    # quick fix to get training dataset size\n","    ds_size = 0\n","    \n","    train_total_accuracy = 0\n","    epoch_loss = 0\n","\n","    start_time = time.time()\n","    for ii in range(np.shape(rand_train)[0]): \n","      #print('batch', ii+1, '/', batch_size)\n","      im, y = data_batch_aug5(datafile_index=num_images*rand_train[ii], num_images=num_images)\n","\n","      # reshaping im to what we want (can do this as data output too)\n","      im = im.reshape(im.shape[2], 1, 100, 100)\n","\n","      y_pred = cn_model(im)\n","      y_pred_cat = nn.functional.softmax(y_pred, dim=1)\n","      \n","\n","      #updated accuracy calculation:\n","      train_predictions = torch.argmax(y_pred, dim=1)\n","      train_label_predictions = torch.argmax(y, dim=1)\n","      train_batch_size = np.shape(train_predictions)[0]\n","      train_batch_accuracy = torch.sum(train_predictions == train_label_predictions).item()/train_batch_size\n","      print(f'train batch accuracy = {100*train_batch_accuracy} %')\n","      train_total_accuracy += train_batch_accuracy\n","\n","      # im doing the backprop after each batch\n","      # (we may just want to do after each epoch)\n","      loss = loss_fn(y_pred, y)\n","      loss.backward()\n","      optimizer.step()\n","      epoch_loss += loss.item()\n","      ds_size += 1\n","\n","    print(\"--- %s seconds ---\" % (time.time() - start_time))\n","\n","    t_loss = epoch_loss / ds_size\n","    print('training loss:', t_loss)\n","    avg_epoch_losses_train.append(t_loss)\n","\n","    train_total_accuracy = 100 * train_total_accuracy / np.shape(rand_train)[0]\n","    print('training accuracy:', train_total_accuracy, '%')\n","    avg_epoch_acc_train.append(train_total_accuracy)\n","\n","    # Validation\n","    cn_model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","      ## quick fix to get some validation data, we want to use more than this \n","      for ii in range(np.shape(rand_test)[0]):\n","        if ii == 0:\n","          im_valid, y_valid = data_batch_aug5(datafile_index=num_images*rand_test[ii], num_images=num_images)\n","          im_valid = im_valid.reshape(im_valid.shape[2], 1, 100, 100)\n","        else:\n","          break\n","      y_pred_valid = cn_model(im_valid)\n","      loss = loss_fn(y_pred_valid, y_valid)\n","      epoch_loss += loss.item()\n","      v_loss = epoch_loss\n","      avg_epoch_losses_val.append(v_loss)\n","      print('validation loss:', v_loss)\n","\n","      valid_predictions = torch.argmax(y_pred_valid, dim=1)\n","      valid_label_predictions = torch.argmax(y_valid, dim=1)\n","      valid_batch_size = np.shape(valid_predictions)[0]\n","      valid_batch_accuracy = torch.sum(valid_predictions == valid_label_predictions).item()/valid_batch_size\n","      print(f'Validation accuracy = {100*valid_batch_accuracy} %')\n","      \n","      avg_epoch_acc_val.append(valid_batch_accuracy)\n","\n","      wandb.log({\"train_loss\": loss, \"valid_loss\": v_loss, \"train_acc\": train_total_accuracy/100, \"valid_acc\": valid_batch_accuracy})\n","      #wandb.watch(cn_model)\n","\n","print(\"DONE TRAINING\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1670195401316,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"12RTbYBaK-wj"},"outputs":[],"source":["'''\n","# For monitoring acc and losses\n","avg_epoch_acc_train = []\n","avg_epoch_acc_val = []\n","avg_epoch_losses_train = []\n","avg_epoch_losses_val = []\n","\n","batch_size = num_images*5#40 \n","\n","print('Model initialized and prepped, begin training...')\n","cn_model.train()\n","for epoch in range(n_epochs):  \n","    print('epoch:', epoch+1)\n","\n","    # quick fix to get training dataset size\n","    ds_size = 0\n","\n","    t_acc_lst = []\n","    epoch_loss = 0\n","    \n","    start_time = time.time()\n","    for ii in range(np.shape(rand_train)[0]): \n","      #print('batch', ii+1, '/', batch_size)\n","      im, y = data_batch_aug5(datafile_index=num_images*rand_train[ii], num_images=num_images)\n","\n","      # reshaping im to what we want (can do this as data output too)\n","      im = im.reshape(im.shape[2], 1, 100, 100)\n","\n","      y_pred = cn_model(im)\n","      y_pred_cat = nn.functional.softmax(y_pred, dim=1)\n","      \n","      ### VERY TEMPORARY WAY OF GETTING ESTIMATE ON ACCURACIES (avg accross all 4)\n","      ### we want to only make one class prediction by picking max, my brain just isnt working\n","      ### this is an overestimate since like if it predicts 0 for all it gets 75%\n","      ### so this is a very strong OVERESTIMATION of accuracy\n","      y_pred_class = y_pred_cat \n","      y_pred_class[y_pred_class >= 0.5] = 1\n","      y_pred_class[y_pred_class < 0.5] = 0\n","      t_acc_batch = torch.sum(y_pred_class == y).numpy()/(num_classes*batch_size) \n","      #print(t_acc_batch)\n","      t_acc_lst.append(t_acc_batch)\n","\n","      # im doing the backprop after each batch\n","      # (we may just want to do after each epoch)\n","      loss = loss_fn(y_pred, y)\n","      loss.backward()\n","      optimizer.step()\n","      epoch_loss += loss.item()\n","      ds_size += 1\n","\n","    print(\"--- %s seconds ---\" % (time.time() - start_time))\n","\n","    t_loss = epoch_loss / ds_size\n","    print('training loss:', t_loss)\n","    avg_epoch_losses_train.append(t_loss)\n","\n","    t_acc = sum(t_acc_lst)/len(t_acc_lst) \n","    print('training accuracy:', t_acc)\n","    avg_epoch_acc_train.append(t_acc)\n","\n","    # Validation\n","    cn_model.eval()\n","    epoch_loss = 0\n","    with torch.no_grad():\n","      ## quick fix to get some validation data, we want to use more than this \n","      for ii in range(np.shape(rand_test)[0]):\n","        if ii == 0:\n","          im_valid, y_valid = data_batch_aug5(datafile_index=num_images*rand_test[ii], num_images=num_images)\n","          im_valid = im_valid.reshape(im_valid.shape[2], 1, 100, 100)\n","        else:\n","          break\n","      y_pred_valid = cn_model(im_valid)\n","      loss = loss_fn(y_pred_valid, y_valid)\n","      epoch_loss += loss.item()\n","      v_loss = epoch_loss\n","      avg_epoch_losses_val.append(v_loss)\n","      print('validation loss:', v_loss)\n","\n","      y_pred_valid_cat = nn.functional.softmax(y_pred_valid, dim=1)\n","      y_pred_valid_cat[y_pred_valid_cat >= 0.5] = 1\n","      y_pred_valid_cat[y_pred_valid_cat < 0.5] = 0\n","      v_acc = torch.sum(y_pred_valid_cat == y_valid).numpy()/(num_classes*batch_size) \n","      print('validation accuracy:', v_acc)\n","      avg_epoch_acc_val.append(v_acc)\n","\n","      wandb.log({\"train_loss\": loss, \"valid_loss\": v_loss, \"train_acc\": t_acc, \"valid_acc\": v_acc})\n","      #wandb.watch(cn_model)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"SQ4FxiqUdOpF"},"source":["Ashley's troubleshooting notes:\n","- I actually run into the issue again when I try num_images = 50, but num_images = 10 seems to be totally fine\n","- I thought the issue was due to us using empty in the data loading function and it using old memory so I did make some changes in that function like replacing that with zeros\n","- C1 might not be working due to different stride and no set learning rate\n","- The paper also seems to have weird learning results...\n","- This should be running faster"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"aborted","timestamp":1670195401317,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"4-K30VyfjWYU"},"outputs":[],"source":["# save model itself \n","torch.save(cn_model.state_dict(), 'test_model1')#, CWD + 'Notebooks/models/')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"aborted","timestamp":1670195401319,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"WKDlFn3F1WxT"},"outputs":[],"source":["# plot accuracy/loss versus epoch\n","fig1 = plt.figure(figsize=(10,3))\n","\n","\n","ax1 = plt.subplot(121)\n","ax1.plot(avg_epoch_acc_train, '--', color='darkslategray', linewidth=2, label='training')\n","ax1.plot(avg_epoch_acc_val, linewidth=2, label='valiation') \n","ax1.legend()\n","ax1.set_title('Model Accuracy')\n","ax1.set_ylabel('Accuracy')\n","ax1.set_xlabel('Epoch')\n","\n","ax2 = plt.subplot(122)\n","ax2.plot(avg_epoch_losses_train, '--', color='crimson', linewidth=2, label='training')\n","ax2.plot(avg_epoch_losses_val, linewidth=2, label='validation')\n","ax2.legend()\n","ax2.set_title('Model Loss')\n","ax2.set_ylabel('Loss')\n","ax2.set_xlabel('Epoch')\n","\n","fig1.savefig('PHYS449_FinalProject/Notebooks/plots/'+'CNN_training_history.png')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ty5Ps1yI1a9q"},"source":["# **Testing - Don't run this yet, it's not done **\n","Here we apply the model to the test set and create a confusion matrix to gauge performance"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1670195401320,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"yEGmwZciDo13"},"outputs":[],"source":["#@title\n","### ADAPT THIS TO GET TEST SET STATS (way to make it not do data augmentation and just stick with original images?)\n","for ii in range(np.shape(rand_test)[0]):\n","  if ii == 0:\n","    pass\n","  else:\n","    image_batch, label_batch = data_batch(datafile_index=50*rand_test[ii], num_images=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1670195401320,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"YaYRm0Xa1llA"},"outputs":[],"source":["#@title\n","# make predictions on test set and compare to real labels\n","preds_test = cn_model.predict(X_test, verbose=1)\n","results = cn_model.evaluate(X_test, y_test) \n","print(\"test loss, valid acc:\", results)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"aborted","timestamp":1670195401321,"user":{"displayName":"Ashley Ferreira","userId":"16034415928337437667"},"user_tz":300},"id":"U1LAiOnE1pJQ"},"outputs":[],"source":["#@title\n","# plot confusion matrix\n","fig2 = plt.figure()\n","cm = confusion_matrix(y_valid, preds_valid)\n","plt.matshow(cm)\n","\n","for (i, j), z in np.ndenumerate(cm):\n","    pyl.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n","plt.title('Confusion matrix (validation data)')\n","plt.colorbar()\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.show()\n","plt.savefig(model_dir_name +'plots/'+'CNN_confusion_matrix.png')"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1RepBaIP_xKekfSf2UxArK4UM_wRBB_t2","timestamp":1670106713766},{"file_id":"1mbvhfFWQWrHRhT4BabaNnULrsF0VZ3Dr","timestamp":1669597836538},{"file_id":"1chVWDY8gyQXL_eIvjrseeJu5Kt2xiFmq","timestamp":1669597459507},{"file_id":"1tIzoBthAZ29ZxZnM4RDggC-oWWT45aXl","timestamp":1669592221343}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.11 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.11"},"vscode":{"interpreter":{"hash":"f8696d3d898bc62b90f4cd7d878fc87a051ec77bbff0b42338ab50969b9d3714"}}},"nbformat":4,"nbformat_minor":0}
