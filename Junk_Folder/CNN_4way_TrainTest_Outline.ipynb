{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfh4ENuykfl"
      },
      "source": [
        "# **PHYS 449: Final Project Notebook**\n",
        "#### Reproducing results from \"Morphological classification of galaxies with deep learning: comparing 3-way and 4-way CNNs\" by Mitchell K. Cavanagh, Kenji Bekki and Brent A. Groves\n",
        "\n",
        "*This all just assumed 4-way classification for now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvlSR1N2ykL9"
      },
      "source": [
        "# **Import Packages**\n",
        "\n",
        "Begin by importing all the needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FnQlrR-O-Jmh"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Flatten, Conv2D, MaxPool2D\n",
        "from keras.layers.core import Dropout\n",
        "import os\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "# connect to w&b for experiment tracking\n",
        "wandb.init(project=\"CNN-4way-test1\", entity=\"449-final project\", config=tf.flags.FLAGS, sync_tensorboard=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va-_oVtsykW4"
      },
      "source": [
        "# **Define Network Structure**\n",
        "We are considering two 2D CNNs, C1 and C2, which are described in the paper and outlined below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "56ljipAIzmXR"
      },
      "outputs": [],
      "source": [
        "def C1(input_shape, unique_labels=4, dropout_rate=0.5):\n",
        "    '''\n",
        "    Defines the 2D Convolutional Neural Network (CNN) called C1\n",
        "    Parameters:    \n",
        "    \n",
        "        input_shape (arr): input shape for network\n",
        "        unique_labels (int): number unique labels \n",
        "        dropout_rate (float): dropout rate as fraction\n",
        "\n",
        "    Returns:\n",
        "        \n",
        "        model (keras model class): CNN to train\n",
        "    '''\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, input_shape=input_shape, activation='relu', kernel_size=(5,5)))\n",
        "    model.add(Conv2D(filters=64, input_shape=input_shape, activation='relu', kernel_size=(5,5)))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "\n",
        "    model.add(Dense(unique_labels, activation='softmax')) \n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lkSyV0tVz6OL"
      },
      "outputs": [],
      "source": [
        "def C2(input_shape, unique_labels=2, dropout_rate=0.5):\n",
        "    '''\n",
        "    Defines the 2D Convolutional Neural Network (CNN) called C2\n",
        "    Parameters:    \n",
        "    \n",
        "        input_shape (arr): input shape for network\n",
        "        unique_labels (int): number unique labels \n",
        "        dropout_rate (float): dropout rate as fraction\n",
        "\n",
        "    Returns:\n",
        "        \n",
        "        model (keras model class): CNN to train\n",
        "    '''\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, input_shape=input_shape, activation='relu', kernel_size=(7,7)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, input_shape=input_shape, activation='relu', kernel_size=(5,5)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=64, input_shape=input_shape, activation='relu', kernel_size=(5,5)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(filters=128, input_shape=input_shape, activation='relu', kernel_size=(3,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "\n",
        "    model.add(Dense(unique_labels, activation='softmax')) \n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyB4yRaICITu"
      },
      "source": [
        "# **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjvEFjidIlKu",
        "outputId": "1c04eb3b-c1d0-4f41-abf5-0af9b8df798c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Import google drive (need to put data folder as shortcut in your local drive My Drive):\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZmT2udOl-dlB"
      },
      "outputs": [],
      "source": [
        "#LOAD THE DATA FROM TXT FILE INTO A BATCH:\n",
        "def data_batch(datafile_index, num_images=10, data_file='/content/drive/MyDrive/data/data_g_band.txt'):\n",
        "    '''\n",
        "    Description:\n",
        "        Access datafile.txt, each row is flattened 110x110 image + 1 label string (E, Sp, S0, Irr+Misc).\n",
        "        Returns an augmented batch of num_images X 40.\n",
        "        The labels are converted to 1D vectors (ex: Sp = [0,0,1,0])\n",
        "        Need to give a datafile_index that tells which rows to pick.\n",
        "    Inputs:\n",
        "        datafile_index: index of row in datafile to load. loads rows datafile_index to datafile_index+num_images.\n",
        "        num_images: number of different images to load per batch, total batch size \n",
        "        is 40 X num_images. (default: 10 (for 40X10 = 400 batch size like in paper)\n",
        "        data_file: datafile full path, need to add shortcut to local Drive. (default: '/content/drive/MyDrive/data/data_g_band.txt')\n",
        "    Outputs:\n",
        "        tensor_input_batch_aug: dimensions: (100, 100, num_images X 40). \n",
        "        tensor_label_batch_aug: dimensions: (num_images X 40, 4)\n",
        "    '''\n",
        "\n",
        "    #data_file = 'data_g_band.txt'\n",
        "\n",
        "    #Take batch of num_images rows from datafile:\n",
        "    with open(data_file, 'r') as f:\n",
        "        rows = f.readlines()[datafile_index:(datafile_index+num_images)]\n",
        "\n",
        "    #for batch size of 400 (augmented), need 10 images\n",
        "    data_batch = np.zeros((num_images,12101), dtype=np.dtype('U10'))\n",
        "    count = 0\n",
        "    for row in rows:\n",
        "        data_batch[count,:] = row.split()\n",
        "        count += 1\n",
        "\n",
        "    #separate label and input:\n",
        "    input_batch_flat = np.array(data_batch[:,:12100], dtype=int)\n",
        "    label_batch = np.array(data_batch[:,-1])\n",
        "\n",
        "    #convert input batch back to a 2D array:\n",
        "    input_batch = np.empty((110,110,np.shape(input_batch_flat)[0]), dtype=int)\n",
        "    for ii in range(np.shape(input_batch_flat)[0]):\n",
        "        input_batch[:,:,ii] = np.reshape(input_batch_flat[ii,:], (110,110))\n",
        "\n",
        "\n",
        "    #convert label batch into into 1D vector: \n",
        "    #E=0, S0=1, Sp=2, Irr+Misc=3\n",
        "    #ex: label = [0,0,1,0] ==> Sp galagy\n",
        "    arr_label_batch = np.empty((np.shape(label_batch)[0],4), dtype=int)\n",
        "\n",
        "    arr_label_batch[:,0] = np.array([label_batch == 'E'], dtype=int)\n",
        "    arr_label_batch[:,1] = np.array([label_batch == 'Sp'], dtype=int)\n",
        "    arr_label_batch[:,2] = np.array([label_batch == 'S0'], dtype=int)\n",
        "    arr_label_batch[:,3] = np.array([label_batch == 'Irr+Misc'], dtype=int)\n",
        "\n",
        "    #test with image plotted\n",
        "    #import matplotlib.pyplot as plt\n",
        "    #plt.imshow(input_batch[:,:,0])\n",
        "    #plt.show()\n",
        "\n",
        "    #NOW AUGMENT THE BATCH (40X more):\n",
        "    input_batch_aug = np.empty((100,100,np.shape(input_batch)[2]*40), dtype=int)\n",
        "    arr_label_batch_aug = np.empty((np.shape(arr_label_batch)[0]*40, 4), dtype=int)\n",
        "\n",
        "    count = 0\n",
        "    for ll in range(np.shape(input_batch)[2]):\n",
        "        #Crop 5X more image (100X100 pixels)\n",
        "        C1 = input_batch[:100,:100,ll]\n",
        "        C2 = input_batch[10:,:100,ll]\n",
        "        C3 = input_batch[:100,10:,ll]\n",
        "        C4 = input_batch[10:,10:,ll]\n",
        "        C5 = input_batch[5:105,5:105,ll]\n",
        "\n",
        "        C = [C1, C2, C3, C4, C5]\n",
        "\n",
        "        for kk in range(5):\n",
        "            #Rotate 4X more image (by 90 deg)\n",
        "            for jj in range(4):\n",
        "                C_R = np.rot90(C[kk], k=jj)\n",
        "                input_batch_aug[:,:,count] = C_R\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "                \n",
        "                input_batch_aug[:,:,count] = np.swapaxes(C_R,0,1)\n",
        "                arr_label_batch_aug[count,:] = arr_label_batch[ll,:]\n",
        "                count += 1\n",
        "\n",
        "\n",
        "    #PUT THE DATA AS A PYTORCH TENSOR:\n",
        "    tensor_input_batch_aug = torch.Tensor(input_batch_aug)\n",
        "    tensor_label_batch_aug = torch.Tensor(arr_label_batch_aug)\n",
        "    \n",
        "    return tensor_input_batch_aug, tensor_label_batch_aug\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6yVoN5dCUtN"
      },
      "source": [
        "# **Sample Data**\n",
        "Here we check that the data files are how we expect them to be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Mg4pcdQQCLjn",
        "outputId": "8b95af01-2788-4633-9f3a-8bd42ab82216"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#Use function defined above:\\n#rand_index = np.random.permutation(1403)\\n#rand_index = np.random.permutation(701)\\nrand_index = np.random.permutation(280)\\n#rand_index = np.random.permutation(140)\\n#shuffled numbers from 0 to 1402 (inclusive)\\n#goes up to 14,030 images, last 4 images load separatly or just ignore\\n#the random index goes up in steps of 10 in the function so randomizes the batching by selected groups of 10 images together\\n\\n#Use this loop for training over entire dataset at each epochs\\nfor ii in range(np.shape(rand_index)[0]):\\n  image_batch, label_batch = data_batch(datafile_index=50*rand_index[ii], num_images=50)\\n  #print(np.shape(image_batch), np.shape(label_batch))\\n  print(ii)\\n\\n#TAKES 40 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 10 IMAGES (400 when augmented)\\n#TAKES 21 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 20 IMAGES (800 when augmented)\\n#TAKES 12 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 50 IMAGES (2000 when augmented)\\n#TAKES 8 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 100 IMAGES (4000 when augmented)\\n\\n#USE 50 images for 12 MIN, good compromise for small enough batches and fast enoguh loading\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "#Use function defined above:\n",
        "#rand_index = np.random.permutation(1403)\n",
        "#rand_index = np.random.permutation(701)\n",
        "rand_index = np.random.permutation(280)\n",
        "#rand_index = np.random.permutation(140)\n",
        "#shuffled numbers from 0 to 1402 (inclusive)\n",
        "#goes up to 14,030 images, last 4 images load separatly or just ignore\n",
        "#the random index goes up in steps of 10 in the function so randomizes the batching by selected groups of 10 images together\n",
        "\n",
        "#Use this loop for training over entire dataset at each epochs\n",
        "for ii in range(np.shape(rand_index)[0]):\n",
        "  image_batch, label_batch = data_batch(datafile_index=50*rand_index[ii], num_images=50)\n",
        "  #print(np.shape(image_batch), np.shape(label_batch))\n",
        "  print(ii)\n",
        "\n",
        "#TAKES 40 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 10 IMAGES (400 when augmented)\n",
        "#TAKES 21 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 20 IMAGES (800 when augmented)\n",
        "#TAKES 12 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 50 IMAGES (2000 when augmented)\n",
        "#TAKES 8 MIN TO LOAD ENTIRE DATASET FOR BATCH OF 100 IMAGES (4000 when augmented)\n",
        "\n",
        "#USE 50 images for 12 MIN, good compromise for small enough batches and fast enoguh loading\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qj1M9LgXI5_R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9eaQI4kCbVT"
      },
      "source": [
        "# **Split Data**\n",
        "Here we split data into trainng, testing datasets (validation split will be done by keras during training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "dWZ89HkS_kMK",
        "outputId": "ed341203-41df-4fb6-9649-52be419d6378"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bfdb13042be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# splitting into training and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ],
      "source": [
        "# splitting into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.15)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un1x2W4GAMex"
      },
      "source": [
        "# **Training**\n",
        "Ideally we use seperate notebooks to train each one\n",
        "\n",
        "C2 uses Adam, wheras C1 uses Adadelta: \n",
        "\n",
        "  https://www.aanda.org/articles/aa/full_html/2020/09/aa37963-20/aa37963-20.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcg_12Uh6ofB"
      },
      "outputs": [],
      "source": [
        "network_to_train = 'C1'\n",
        "\n",
        "# define hyperparameters of training\n",
        "if network_to_train == 'C1':\n",
        "  n_epochs = 13\n",
        "  # can't find learning rate mentioned so I'm leaving it as default for now\n",
        "  opt = optimizers.Adadelta()\n",
        "  cn_model = C1(X_train.shape[1:])\n",
        "elif network_to_train == 'C2':\n",
        "  n_epochs = 20\n",
        "  lr = 2*pow(10,-4)\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "  cn_model = C2(X_train.shape[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCWI5abdBa1Q"
      },
      "outputs": [],
      "source": [
        "# show model architecture\n",
        "cn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M_9JE382TpH"
      },
      "outputs": [],
      "source": [
        "# setup W&B tracking \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1pE38yD2dp4"
      },
      "outputs": [],
      "source": [
        "# add early stopping (optional, can just take epochs from paper, if used set epochs to 100 as max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvuJk18LAlsd"
      },
      "outputs": [],
      "source": [
        " # train the model \n",
        "cn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', 'loss'])\n",
        "\n",
        "print('Model initialized and prepped, begin training...')\n",
        "classifier = cn_model.fit(X_train_1layer, y_train, epochs=n_epochs, validation_data=(X_test_1layer, y_test)) # fix, keep test seperate and use validation split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6jZTCtYDfGF"
      },
      "source": [
        "^ add specific batch data with keras? worse comes to worse we do it in pytorch but these articles seem helpful to get it going\n",
        "\n",
        "1.  https://meatba11.medium.com/keras-loading-and-processing-images-in-batches-1cff1b0f4aa4\n",
        "2. https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
        "3. https://stackoverflow.com/questions/61021025/split-data-into-batches\n",
        "4. https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "\n",
        "And more online, so I think we can figure it out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKDlFn3F1WxT"
      },
      "outputs": [],
      "source": [
        "# plot accuracy/loss versus epoch\n",
        "fig1 = plt.figure(figsize=(10,3))\n",
        "\n",
        "ax1 = plt.subplot(121)\n",
        "ax1.plot(classifier.history['accuracy'], color='darkslategray', linewidth=2, label='training')\n",
        "ax1.plot(classifier.history['val_accuracy'], linewidth=2, label='valiation') \n",
        "ax1.legend()\n",
        "ax1.set_title('Model Accuracy')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "\n",
        "ax2 = plt.subplot(122)\n",
        "ax2.plot(classifier.history['loss'], color='crimson', linewidth=2, label='training')\n",
        "ax2.plot(classifier.history['val_loss'], linewidth=2, label='validation')\n",
        "ax2.legend()\n",
        "ax2.set_title('Model Loss')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "\n",
        "fig1.savefig(model_dir_name +'/plots/'+'CNN_training_history.png')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty5Ps1yI1a9q"
      },
      "source": [
        "# **Testing**\n",
        "Here we apply the model to the test set and create a confusion matrix to gauge performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaYRm0Xa1llA"
      },
      "outputs": [],
      "source": [
        "# make predictions on test set and compare to real labels\n",
        "preds_test = cn_model.predict(X_test, verbose=1)\n",
        "results = cn_model.evaluate(X_test, y_test) \n",
        "print(\"test loss, valid acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1LAiOnE1pJQ"
      },
      "outputs": [],
      "source": [
        "# plot confusion matrix\n",
        "fig2 = plt.figure()\n",
        "cm = confusion_matrix(y_valid, preds_valid)\n",
        "plt.matshow(cm)\n",
        "\n",
        "for (i, j), z in np.ndenumerate(cm):\n",
        "    pyl.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
        "plt.title('Confusion matrix (validation data)')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()\n",
        "plt.savefig(model_dir_name +'plots/'+'CNN_confusion_matrix.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "f8696d3d898bc62b90f4cd7d878fc87a051ec77bbff0b42338ab50969b9d3714"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
